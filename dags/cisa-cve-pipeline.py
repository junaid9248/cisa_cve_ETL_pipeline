from airflow import DAG
from airflow.providers.google.cloud.operators.cloud_run import CloudRunExecuteJobOperator
from datetime import datetime
from src.config import GCLOUD_PROJECTNAME
import logging 
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

from datetime import timedelta
import pendulum as pend
local_tz = pend.timezone('America/Chicago')
start_date = pend.datetime(2026, 1, 10, tz=local_tz)

default_args = {
    'owner': 'junaid',
    'retries': 1,
    'start_date': start_date,
    'retry_delay': timedelta(seconds = 30),
    # Adding a buffer window for tasks especially raws extraction task so it does NOT time out!
    'execution_timeout': timedelta(hours=3),
    'max_active_runs': 1,
}

with DAG(
 dag_id='cve_elt_pipeline',
    schedule ='@daily',
    default_args= default_args,
    description='Extract raw cve jsons from CISA Vulnrichment gihtub repo into GCS bucket -> Transform into structured table formats -> Load into BigQuery-> perform quality checks'

) as dag:
    # TASK 1: Extract the raws from cisa repo and post ndjsons to
    logging.info("Setting up the extract task")
    extract_raws = CloudRunExecuteJobOperator(
        task_id = 'elt_extraction',
        project_id=GCLOUD_PROJECTNAME,
        region='us-central1',
        job_name='elt-run-job',
        overrides={
            'container_overrides':[{'args':['python','main.py','--task', 
                                            'extract', 
                                            '--cloud']}]
        }
    )
    # TASK 2: Load ndjsons to bronze table
    logging.info("Setting up the load task")
    load_to_bronze = CloudRunExecuteJobOperator(
        task_id = 'elt_load',
        project_id=GCLOUD_PROJECTNAME,
        region='us-central1',
        job_name='elt-run-job',
        overrides={
            'container_overrides':[{'args':['python',
                                            'main.py',
                                            '--task',
                                            'load', 
                                            '--cloud']}]
        }
    )
    #TASK 3: Transform bronze table to final table
    logging.info("Setting up the transform task")
    transform_bronze_final = CloudRunExecuteJobOperator(
        task_id = 'elt_transform',
        project_id=GCLOUD_PROJECTNAME,
        region='us-central1',
        job_name='elt-run-job',
        overrides={
            'container_overrides':[{'args':['python',
                                            'main.py',
                                            '--task',
                                            'transform',
                                            '--cloud']}]
        }
    )

    # Dependencies
    extract_raws >> load_to_bronze >> transform_bronze_final